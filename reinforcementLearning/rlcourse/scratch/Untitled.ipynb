{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using:  cuda:1\n",
      "using:  cuda:1\n",
      "... saving checkpoint...\n",
      "... saving checkpoint...\n",
      "episode: 0\tscore: -21.0\tavg score: -21.0\tbest score: -21.0\teps: 1.00\tsteps: 783\ttime: 13.311\n",
      "... saving checkpoint...\n",
      "... saving checkpoint...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dqn_agent import DQNAgent\n",
    "from utils import make_env, plot_learning_curve\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "\n",
    "\n",
    "ENV = 'PongNoFrameskip-v4'\n",
    "NUM_GAMES = 1001\n",
    "MEM_SIZE = 96000\n",
    "BATCH_SIZE = 32\n",
    "LR = .0001\n",
    "GAMMA = .99\n",
    "EPSILON = 1.0\n",
    "EPSILON_MIN = 0.1\n",
    "EPSILON_DECAY = 5e-6\n",
    "ALGORITHM = 'DQNAgent'\n",
    "POLICY_UPDATE = 1000\n",
    "CHECKPOINT_DIR = 'models/'\n",
    "FIGURES_DIR = 'figures/'\n",
    "MOVMEAN = 100\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = make_env(ENV)\n",
    "    best_score = -np.inf\n",
    "    load_checkpoint = False\n",
    "    agent = DQNAgent(gamma=GAMMA, epsilon=EPSILON, lr=LR, input_dims=env.observation_space.shape,\n",
    "                     n_actions=env.action_space.n, mem_size=MEM_SIZE, eps_min=EPSILON_MIN, batch_size=BATCH_SIZE,\n",
    "                     replace_count=POLICY_UPDATE, eps_dec=EPSILON_DECAY, checkpoint_dir=CHECKPOINT_DIR, algorithm=ALGORITHM,\n",
    "                     env_name=ENV)\n",
    "\n",
    "    if load_checkpoint:\n",
    "        agent.load_models()\n",
    "\n",
    "    file_name = agent.algorithm + \"_\" + agent.env_name + \"_lr-\" + str(agent.lr) + \"_\" + str(NUM_GAMES) + \"-games\"\n",
    "    figure_file = FIGURES_DIR + file_name + \".png\"\n",
    "\n",
    "    n_steps = 0\n",
    "    scores = []\n",
    "    eps_hist = []\n",
    "    steps_arr = []\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    tic1 = time.perf_counter()\n",
    "    for i in range(NUM_GAMES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        obs = env.reset()\n",
    "        while not done:\n",
    "            action = agent.choose_action(obs)\n",
    "            next_obs, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "\n",
    "            # if training store the transition\n",
    "            if not load_checkpoint:\n",
    "                agent.store_transition(obs, action, reward, next_obs, int(done))\n",
    "                agent.learn()\n",
    "            obs = next_obs\n",
    "            n_steps += 1\n",
    "        scores.append(score)\n",
    "        steps_arr.append(n_steps)\n",
    "        eps_hist.append(agent.epsilon)\n",
    "\n",
    "        avg = np.mean(scores[-MOVMEAN:])\n",
    "        if avg > best_score:\n",
    "            if not load_checkpoint:\n",
    "                agent.save_models()\n",
    "            best_score = avg\n",
    "\n",
    "        plot_learning_curve(steps_arr, scores, eps_hist, figure_file)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            toc1 = time.perf_counter()\n",
    "            print(\"episode: {}\\tscore: {:.1f}\\tavg score: {:.1f}\\tbest score: {:.1f}\\teps: {:.2f}\\tsteps: {}\\ttime: {:.3f}\".format(i, score, avg, best_score, agent.epsilon, n_steps, (toc1-tic1)))\n",
    "            tic1 = time.perf_counter()\n",
    "    toc\n",
    "    print(\"elapsed training time: {:.3f}\".format((toc-tic)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
